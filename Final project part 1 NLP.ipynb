{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data\n",
    "For the SVD, we need a corpus comprising a list of questions, since we are using just the questions (not the answers) to make recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is one thing you always wanted as a kid, but never got?',\n",
       " 'if you could bring someone famous back from the grave, who would you choose?',\n",
       " 'where do you not mind waiting?',\n",
       " 'if you could lock up one person in a mental institution, who would it be?',\n",
       " 'if you could project yourself into the past, where would you go?',\n",
       " 'what would you refuse to do for one million dollars?',\n",
       " 'are you a good swimmer?',\n",
       " 'are you left or right handed?',\n",
       " 'how old are you?',\n",
       " 'what football team do you support?',\n",
       " 'do you correct peoples mistakes?',\n",
       " 'if you and a friend both wanted the same thing would you let the friend get it first?',\n",
       " 'if you saw someone drop a Â£10 note, would you claim it for your own or try to return it to them?',\n",
       " 'if you met a genie who offered you three wishes, what would you wish for? (more wishes does not count)',\n",
       " 'how many languages do you speak?',\n",
       " 'have you ever brought a present for someone that they hated/disliked?',\n",
       " 'are you a good comedian?',\n",
       " 'if you were prime minister/ruler of the world what laws would you make?',\n",
       " 'how long could you go without talking?',\n",
       " 'have you ever made a ball of twine or rubberbands?',\n",
       " 'what are some of your bad habits?',\n",
       " '9. what are your biggest pet peeves?',\n",
       " 'what are some of your favorite musicians?',\n",
       " 'do you get jealous easily?',\n",
       " 'how many concerts have you been to? who did you see for your first concert?',\n",
       " 'what is one talent you have? / one that you wish that you had?',\n",
       " 'last person you texted? what did your text say?']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data = pd.read_csv(\"Q&A.csv\", index_col=\"Questions\")\n",
    "qa_data.index = qa_data.index.str.lower() # all questions lowercase for consistency\n",
    "qa_corpus = list(qa_data.index)\n",
    "qa_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Luckily, we don't have to change too much since the questions are already in the right format. However, we still want to simplify the information into the bare necessities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words that don't provide much information\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def make_df(corpus):\n",
    "    # pipeline that uses the Tf-Idf method to remove useless words and categorize the questions by semantic similarity\n",
    "    pipe = [('tfidf', TfidfVectorizer(stop_words=stop_words, \n",
    "                        token_pattern=\"\\\\b[a-zA-Z][a-zA-Z]+\\\\b\", \n",
    "                        min_df=1)),\n",
    "       ('lsa', TruncatedSVD(2)),\n",
    "       ('normalizer', Normalizer())] # each value is either 0 or 1 to make the similarity more clear\n",
    "    \n",
    "    # then creates an SVD dataframe of the specified number of components, to be used by our recommendation system\n",
    "    # (like with movie recommendations)\n",
    "    pipeline = Pipeline(pipe)\n",
    "    dtm_svd = pipeline.fit_transform(corpus)\n",
    "    #dtm_svd = Normalizer(copy=False).fit_transform(X_svd) ????\n",
    "\n",
    "    return pd.DataFrame(dtm_svd.round(10),\n",
    "                 index=corpus,\n",
    "                 columns=[\"component_1\",\"component_2\" ])\n",
    "\n",
    "make_df(qa_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation and Chatbot\n",
    "Now that everything is set up, we can get to the code for the actual question recommender and have a user input questions and receive a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is AskTwitterBot.\n",
      "\n",
      "What question do you have?what are you?\n",
      "\n",
      "Closest to 'what are you?': what is one talent you have? / one that you wish that you had?\n",
      "Umm ... I can touch my nose with my tounge ? And I'm double jointed . ðŸ¤·ðŸ»â€â™€ï¸\n",
      "Any other questions? (enter if not)good job you fool\n",
      "\n",
      "Closest to 'good job you fool': are you a good swimmer?\n",
      "No ðŸ˜”\n",
      "Any other questions? (enter if not)how can i get to australia?\n",
      "\n",
      "Closest to 'how can i get to australia?': how old are you?\n",
      "10\n",
      "Any other questions? (enter if not)how young are uo?\n",
      "\n",
      "Closest to 'how young are uo?': how many languages do you speak?\n",
      "english and im getting p good at french. i want to learn dutch, german, and itallian as well\n",
      "Any other questions? (enter if not)how young are you\n",
      "\n",
      "Closest to 'how young are you': how old are you?\n",
      "15\n",
      "Any other questions? (enter if not)how many years of age do you have\n",
      "\n",
      "Closest to 'how many years of age do you have': how many languages do you speak?\n",
      "Only. English\n",
      "Any other questions? (enter if not)do you like nico johnson?\n",
      "\n",
      "Closest to 'do you like nico johnson?': do you correct peoples mistakes?\n",
      "if necessary, yes\n",
      "Any other questions? (enter if not)do you blah blah\n",
      "\n",
      "Closest to 'do you blah blah': how long could you go without talking?\n",
      "probably about 1 to 2 days that's it though\n",
      "Any other questions? (enter if not)do you shuck corn?\n",
      "\n",
      "Closest to 'do you shuck corn?': what is one talent you have? / one that you wish that you had?\n",
      "I can interpret dreams. Wish I could read people better.\n",
      "Any other questions? (enter if not)\n"
     ]
    }
   ],
   "source": [
    "def get_similar_sentences(compare_sentence, corpus, num_recom):\n",
    "    # using a temp corpus so as not to alter the original\n",
    "    temp_corpus = [] + corpus\n",
    "    \n",
    "    # if the question being asked is already in our database, we don't need it twice\n",
    "    if compare_sentence not in temp_corpus:\n",
    "        temp_corpus.append(compare_sentence)\n",
    "    \n",
    "    df = make_df(temp_corpus) # now we can make the SVD dataframe\n",
    "    temp_corpus.clear()\n",
    "    comp = df.index.get_loc(compare_sentence) # index of our question\n",
    "    \n",
    "    recs = []\n",
    "    for sentence in range(df.shape[0]):\n",
    "        if sentence != comp:\n",
    "            # dot product of our question and another sentence to measure their semantic similarity\n",
    "            recs.append((np.dot(df.iloc[comp], df.iloc[sentence]), sentence))\n",
    "            \n",
    "    # sorting questions by most -> least similar so we can respond with the \"closest\" answer\n",
    "    recs.sort(reverse = True)\n",
    "    final_rec = [df.iloc[recs[i][1]].name for i in range(num_recom)]\n",
    "    return final_rec\n",
    "\n",
    "def bot():\n",
    "    # get user input\n",
    "    q = input(\"Hello, my name is AskTwitterBot.\\n\\nWhat question do you have?\").lower().strip()\n",
    "    while q:\n",
    "        # find the closest question\n",
    "        closest_q = get_similar_sentences(q, qa_corpus, 1)[0]\n",
    "        print(f\"\\nClosest to '{q}':\", closest_q)\n",
    "        \n",
    "        # randomly select a response from the possible responses\n",
    "        ans = qa_data.loc[closest_q].dropna()\n",
    "        x = rand.randint(0, len(ans) - 1)\n",
    "        print(ans.values[x])\n",
    "        \n",
    "        q = input(\"Any other questions? (enter if not)\").lower().strip()\n",
    "\n",
    "bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
